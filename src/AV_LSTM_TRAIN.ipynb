{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elliot-brooks/nlu-coursework/blob/main/src/av_model_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX1sFbdQgv_W"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gwaoFym8guws"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import LSTM, Dense, Embedding, Input, concatenate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd7312r4g-Fs"
      },
      "source": [
        "# Load training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pvOX2Y9chCJ6"
      },
      "outputs": [],
      "source": [
        "training_corpus = pd.read_csv(\"train.csv\", encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h7JHjvThCjX"
      },
      "source": [
        "# Pre-process training data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Pre-process training data\n",
        "- Case Folding\n",
        "- Separate all punctuation with spaces\n",
        "'''\n",
        "def preprocess(string):\n",
        "  output = str(string).lower()\n",
        "  separated_string = re.sub(r'([^\\w\\s])', r' \\1 ', str(string))\n",
        "  return output\n",
        "\n",
        "'''\n",
        "Tokenise processed data\n",
        "- OOV token = \"UNK\"\n",
        "- Pre-pad each sequence\n",
        "'''\n",
        "def tokenise(data, column_1, column_2, max_sequence_length) :\n",
        "  first_pairs = data[column_1].tolist()\n",
        "  second_pairs = data[column_2].tolist()\n",
        "\n",
        "  # init tokeniser\n",
        "  tk = Tokenizer(oov_token='UNK', lower=True)\n",
        "  tk.fit_on_texts(first_pairs + second_pairs)\n",
        "\n",
        "  # tokenise texts\n",
        "  tokenised_first_pairs = tk.texts_to_sequences(first_pairs)\n",
        "  tokenised_second_pairs = tk.texts_to_sequences(second_pairs)\n",
        "\n",
        "  # pad sequences\n",
        "  tokenised_first_pairs = pad_sequences(tokenised_first_pairs, maxlen=max_sequence_length, padding='pre')\n",
        "  tokenised_second_pairs = pad_sequences(tokenised_second_pairs, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "  # return vocabulary\n",
        "  vocab = tk.word_index\n",
        "\n",
        "  return tokenised_first_pairs, tokenised_second_pairs, vocab\n",
        "\n",
        "def prepare_data(data, sequence_size) :\n",
        "  data[\"text_1\"] = data[\"text_1\"].apply(lambda x: preprocess(x))\n",
        "  data[\"text_2\"] = data[\"text_2\"].apply(lambda x: preprocess(x))\n",
        "  sequences_1, sequences_2, vocab = tokenise(data, \"text_1\", \"text_2\", sequence_size)\n",
        "  return [sequences_1, sequences_2], vocab\n",
        "\n",
        "SEQUENCE_SIZE = 150\n",
        "pairwise_labels = np.array(training_corpus['label'])\n",
        "input_data, vocab = prepare_data(training_corpus, SEQUENCE_SIZE)"
      ],
      "metadata": {
        "id": "Kh38fXs3N_tk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo3REjQwhGU_"
      },
      "source": [
        "# Define Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iRj2twAchU33",
        "outputId": "753eb4a6-8213-49eb-d3fc-394deb0f6813",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 150)]                0         []                            \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 150)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)     (None, 150, 100)             1062880   ['input_5[0][0]',             \n",
            "                                                          0          'input_6[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 128)                  117248    ['embedding_2[0][0]',         \n",
            "                                                                     'embedding_2[1][0]']         \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 256)                  0         ['lstm_2[0][0]',              \n",
            " )                                                                   'lstm_2[1][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    257       ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10746305 (40.99 MB)\n",
            "Trainable params: 10746305 (40.99 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(vocab) + 1\n",
        "\n",
        "# Define input layers\n",
        "left_input = Input(shape=(SEQUENCE_SIZE,), dtype='int32')\n",
        "right_input = Input(shape=(SEQUENCE_SIZE,), dtype='int32')\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "embedding_layer = Embedding(vocab_size, EMBEDDING_DIM, input_length=SEQUENCE_SIZE)\n",
        "left_encoding = embedding_layer(left_input)\n",
        "right_encoding = embedding_layer(right_input)\n",
        "\n",
        "# Create Shared LSTM model\n",
        "LSTM_UNITS = 128\n",
        "shared_lstm = LSTM(LSTM_UNITS)\n",
        "left_output = shared_lstm(left_encoding)\n",
        "right_output = shared_lstm(right_encoding)\n",
        "\n",
        "# Concatenate the outputs\n",
        "concatenated_output = concatenate([left_output, right_output])\n",
        "\n",
        "# Dense layer for probability distribution\n",
        "output = Dense(1, activation='sigmoid')(concatenated_output)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=[left_input, right_input], outputs=output)\n",
        "\n",
        "# Summarise Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyEe9fxZhKad"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4xylsLNIhVLd",
        "outputId": "1b1b584d-7969-42ba-dab8-0f24c5b5a5c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 76s 78ms/step - loss: 0.6897 - accuracy: 0.5226\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.5740 - accuracy: 0.7064\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.2840 - accuracy: 0.8779\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 19s 20ms/step - loss: 0.1159 - accuracy: 0.9544\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 20s 21ms/step - loss: 0.0558 - accuracy: 0.9789\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 0.0295 - accuracy: 0.9894\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.0201 - accuracy: 0.9937\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 0.0153 - accuracy: 0.9949\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 19s 20ms/step - loss: 0.0101 - accuracy: 0.9968\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 17s 19ms/step - loss: 0.0111 - accuracy: 0.9963\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fdd1c6c1510>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model.fit(input_data, pairwise_labels, epochs=6, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHHs6mBehNBR"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "r_EptFJXhVyf"
      },
      "outputs": [],
      "source": [
        "model.save(\"AV_LSTM_MODEL\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip model file\n",
        "!zip -r /content/LSTM_MODEL.zip /content/AV_LSTM_MODEL"
      ],
      "metadata": {
        "id": "e3lHpKM7FkSg",
        "outputId": "a409ab94-1670-49ed-a2bb-250bc64a559b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/AV_LSTM_MODEL/ (stored 0%)\n",
            "updating: content/AV_LSTM_MODEL/keras_metadata.pb (deflated 88%)\n",
            "updating: content/AV_LSTM_MODEL/variables/ (stored 0%)\n",
            "updating: content/AV_LSTM_MODEL/variables/variables.index (deflated 59%)\n",
            "updating: content/AV_LSTM_MODEL/variables/variables.data-00000-of-00001 (deflated 10%)\n",
            "updating: content/AV_LSTM_MODEL/fingerprint.pb (stored 0%)\n",
            "updating: content/AV_LSTM_MODEL/assets/ (stored 0%)\n",
            "updating: content/AV_LSTM_MODEL/saved_model.pb (deflated 90%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}