{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elliot-brooks/nlu-coursework/blob/main/src/av_model_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX1sFbdQgv_W"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gwaoFym8guws"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import LSTM, Dense, Embedding, Input, concatenate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "FIRST_PAIR = 0\n",
        "SECOND_PAIR = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd7312r4g-Fs"
      },
      "source": [
        "# Load training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pvOX2Y9chCJ6"
      },
      "outputs": [],
      "source": [
        "training_corpus = pd.read_csv(\"train.csv\", encoding='utf-8')\n",
        "# pairwise_labels = np.array(training_corpus['label'])\n",
        "# pairwise_data = np.array(training_corpus[['text_1', 'text_2']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h7JHjvThCjX"
      },
      "source": [
        "# Pre-process training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tQCBFdCvhUit"
      },
      "outputs": [],
      "source": [
        "def preprocess(string):\n",
        "  output = str(string).lower()\n",
        "  separated_string = re.sub(r'([^\\w\\s])', r' \\1 ', str(string))\n",
        "  return output\n",
        "\n",
        "training_corpus[\"text_1\"] = training_corpus[\"text_1\"].apply(lambda x: preprocess(x))\n",
        "training_corpus[\"text_2\"] = training_corpus[\"text_2\"].apply(lambda x: preprocess(x))\n",
        "pairwise_labels = np.array(training_corpus['label'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenise(data, column_1, column_2, max_sequence_length) :\n",
        "  first_pairs = training_corpus[column_1].tolist()\n",
        "  second_pairs = training_corpus[column_2].tolist()\n",
        "\n",
        "  # init tokeniser\n",
        "  tk = Tokenizer(oov_token='UNK', lower=True)\n",
        "  tk.fit_on_texts(first_pairs + second_pairs)\n",
        "\n",
        "  # tokenise texts\n",
        "  tokenised_first_pairs = tk.texts_to_sequences(first_pairs)\n",
        "  tokenised_second_pairs = tk.texts_to_sequences(second_pairs)\n",
        "\n",
        "  # pad sequences\n",
        "  tokenised_first_pairs = pad_sequences(tokenised_first_pairs, maxlen=max_sequence_length, padding='pre')\n",
        "  tokenised_second_pairs = pad_sequences(tokenised_second_pairs, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "  # return vocabulary\n",
        "  vocab = tk.word_index\n",
        "\n",
        "  return tokenised_first_pairs, tokenised_second_pairs, vocab\n",
        "\n",
        "SEQUENCE_SIZE = 150\n",
        "sequences_1, sequences_2, vocab = tokenise(training_corpus, \"text_1\", \"text_2\", SEQUENCE_SIZE)"
      ],
      "metadata": {
        "id": "Kh38fXs3N_tk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences_1[0])\n",
        "print(sequences_2[0])"
      ],
      "metadata": {
        "id": "aECEykqSXKj7",
        "outputId": "a9d74aad-9dc1-4839-b27a-de523b3d9c3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    0     0     0     0     0     0     0     0     0     0     0  1623\n",
            "   755  2397   385   133     3    30  9015     3   184   665     6    30\n",
            "  2829   592  1425  7812    67    32  4378    36   216  1218  2366   432\n",
            " 13494     5    30   670   419  6011 42618    32    95   302   747    18\n",
            "     4   928   215   216   787   746    11   153    23   187     3    73\n",
            "    18    97     7  1474    16     8     4  3761   133     8  9281    14\n",
            "    21   259     6     2  3096    46  3039     5     7    85   542    14\n",
            "    85    62  2162   670  2421    84    14   182    14    57   266    23\n",
            "   120     6     4   127     3   123    18    14    95     2    46  1891\n",
            "    37  2350     7  2549  2506  3267   554    14   220   399   197   315\n",
            "     7  2506  3267   220    16    46     9  2011     5  1247    63    34\n",
            "     6   196  1116   199   568     6   849   329    45   985  5654     5\n",
            " 16969  4728  1524   534     2   751]\n",
            "[    0     0     0     0     0     0     0     0     0     0     0  1245\n",
            "  7416  2159 20367  4284  9095     9  9997    29     2  1245    22  3012\n",
            "   817 49983  1349  8171 20367  1634     2  4254    19     4  1492     3\n",
            "   184     4   227  3793  2217    15   539    24 49983  2143    11     5\n",
            "   564    14    15   539    60  1220     9     4  1404     5  2435   492\n",
            "   333 20367     5 49983    18     4   227  3016     5   773    84   161\n",
            "  1807    59    63    84   681     5  8407    24     2   759    48   799\n",
            "    62     6     2  3016     5   773    27  2050     7    80    45 19096\n",
            " 87846   301    21    28   430     2    74   123     5 12891    95     2\n",
            "  1285   329   438    22 58112     5 28609   645    27   974  4290   745\n",
            "    57    67     3   466     2   710    15     2   566     3   319    16\n",
            "    46  5683     3  8171     5  9095  9095     9    57   286     7   192\n",
            "   248    32    21   120     6    36]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo3REjQwhGU_"
      },
      "source": [
        "# Define Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iRj2twAchU33",
        "outputId": "2fc9bcff-f066-4930-f635-0cff75603806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 150)]                0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 150)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 150, 100)             1062880   ['input_1[0][0]',             \n",
            "                                                          0          'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 128)                  117248    ['embedding[0][0]',           \n",
            "                                                                     'embedding[1][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 256)                  0         ['lstm[0][0]',                \n",
            "                                                                     'lstm[1][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1)                    257       ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10746305 (40.99 MB)\n",
            "Trainable params: 10746305 (40.99 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(vocab) + 1\n",
        "\n",
        "# Define input layers\n",
        "left_input = Input(shape=(SEQUENCE_SIZE,), dtype='int32')\n",
        "right_input = Input(shape=(SEQUENCE_SIZE,), dtype='int32')\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "embedding_layer = Embedding(vocab_size, EMBEDDING_DIM, input_length=SEQUENCE_SIZE)\n",
        "left_encoding = embedding_layer(left_input)\n",
        "right_encoding = embedding_layer(right_input)\n",
        "\n",
        "# Shared LSTM layer\n",
        "lstm_units = 128\n",
        "shared_lstm = LSTM(lstm_units)\n",
        "left_output = shared_lstm(left_encoding)\n",
        "right_output = shared_lstm(right_encoding)\n",
        "\n",
        "# Concatenate the outputs\n",
        "concatenated_output = concatenate([left_output, right_output])\n",
        "\n",
        "# Dense layer for classification\n",
        "output = Dense(1, activation='sigmoid')(concatenated_output)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=[left_input, right_input], outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyEe9fxZhKad"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4xylsLNIhVLd",
        "outputId": "0441bd83-5ee7-4327-a272-55471977cb13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 98s 99ms/step - loss: 0.6919 - accuracy: 0.5206\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 36s 39ms/step - loss: 0.6020 - accuracy: 0.6819\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 25s 26ms/step - loss: 0.3344 - accuracy: 0.8558\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 20s 21ms/step - loss: 0.1425 - accuracy: 0.9443\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 20s 22ms/step - loss: 0.0619 - accuracy: 0.9770\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 19s 20ms/step - loss: 0.0324 - accuracy: 0.9890\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 17s 19ms/step - loss: 0.0207 - accuracy: 0.9930\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.0137 - accuracy: 0.9954\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 17s 19ms/step - loss: 0.0099 - accuracy: 0.9968\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.0087 - accuracy: 0.9973\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cec56967cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def combine_pairwise_data(sequence_1, sequence_2) :\n",
        "  tuple_list = []\n",
        "  for i in range(len(sequence_1)) :\n",
        "    tuple_list.append((sequence_1[i], sequence_2[i]))\n",
        "  return np.array(tuple_list)\n",
        "\n",
        "input_data = combine_pairwise_data(sequences_1, sequences_2)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit([sequences_1, sequences_2], pairwise_labels, epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHHs6mBehNBR"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "r_EptFJXhVyf"
      },
      "outputs": [],
      "source": [
        "model.save(\"AV_LSTM_MODEL\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/LSTM_MODEL.zip /content/AV_LSTM_MODEL"
      ],
      "metadata": {
        "id": "e3lHpKM7FkSg",
        "outputId": "21da2f93-7056-4832-ea34-24e1c4c70f8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/AV_LSTM_MODEL/ (stored 0%)\n",
            "  adding: content/AV_LSTM_MODEL/keras_metadata.pb (deflated 88%)\n",
            "  adding: content/AV_LSTM_MODEL/variables/ (stored 0%)\n",
            "  adding: content/AV_LSTM_MODEL/variables/variables.data-00000-of-00001 (deflated 10%)\n",
            "  adding: content/AV_LSTM_MODEL/variables/variables.index (deflated 59%)\n",
            "  adding: content/AV_LSTM_MODEL/fingerprint.pb (stored 0%)\n",
            "  adding: content/AV_LSTM_MODEL/saved_model.pb (deflated 89%)\n",
            "  adding: content/AV_LSTM_MODEL/assets/ (stored 0%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}